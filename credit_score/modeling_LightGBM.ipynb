{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nataliamarko/Documents/Kaggle/home_credit_risk_score'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "test_data = joblib.load('/Users/nataliamarko/Documents/Kaggle/home_credit_risk_score/temp_data/test_data_pp.pkl')\n",
    "train_data = joblib.load('/Users/nataliamarko/Documents/Kaggle/home_credit_risk_score/temp_data/train_data_pp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 23451, number of negative: 740032\n",
      "[LightGBM] [Info] Total Bins 9237\n",
      "[LightGBM] [Info] Number of data points in the train set: 763483, number of used features: 133\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030716 -> initscore=-3.451780\n",
      "[LightGBM] [Info] Start training from score -3.451780\n",
      "Validation ROC AUC: 0.6976373009689332\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 24543, number of negative: 738633\n",
      "[LightGBM] [Info] Total Bins 9026\n",
      "[LightGBM] [Info] Number of data points in the train set: 763176, number of used features: 133\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.032159 -> initscore=-3.404374\n",
      "[LightGBM] [Info] Start training from score -3.404374\n",
      "Validation ROC AUC: 0.7019941920067088\n",
      "BASE LINE -Overall Validation ROC AUC is: 0.699815746487821 ± 0.002178445518887795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import gc\n",
    "\n",
    "\n",
    "# Train the model using LightGBM\n",
    "y = train_data['target']\n",
    "X = train_data.drop(['target', 'case_id', 'WEEK_NUM'], axis=1)\n",
    "weeks = train_data[\"WEEK_NUM\"]\n",
    "\n",
    "# Standardize the data before splitting\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_, X_test, y_train_, y_test = train_test_split(X, y, \n",
    "                                                      test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train data into train and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_, y_train_, \n",
    "                                                      test_size=0.2, random_state=42)\n",
    "\n",
    "cv = GroupKFold(n_splits=2)\n",
    "\n",
    "lgbm_model = LGBMClassifier(force_col_wise=True, \n",
    "                            random_state=42)\n",
    "\n",
    "valid_roc_aucs = []\n",
    "for idx_train, idx_valid in cv.split(X_scaled, y, groups=weeks):\n",
    "    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "    \n",
    "    # Train the model\n",
    "    lgbm_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=0)]\n",
    "    )\n",
    "    # Predict on validation set\n",
    "    y_valid_pred_proba = lgbm_model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    # Evaluate model on validation set\n",
    "    valid_roc_auc = roc_auc_score(y_valid, y_valid_pred_proba)\n",
    "    print(f'Validation ROC AUC: {valid_roc_auc}')\n",
    "    valid_roc_aucs.append(valid_roc_auc)\n",
    "\n",
    "print(f'BASE LINE -Overall Validation ROC AUC is: {np.mean(valid_roc_aucs)} ± {np.std(valid_roc_aucs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASE LINE -Overall Validation ROC AUC is: 0.699815746487821 ± 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[675]\ttraining's auc: 0.748878\ttraining's binary_logloss: 0.124052\tvalid_1's auc: 0.694791\tvalid_1's binary_logloss: 0.134517\n",
      "Fold Validation complex model ROC AUC: 0.6947911977409509\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[883]\ttraining's auc: 0.751822\ttraining's binary_logloss: 0.124909\tvalid_1's auc: 0.705666\tvalid_1's binary_logloss: 0.130817\n",
      "Fold Validation complex model ROC AUC: 0.7056661063375721\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[771]\ttraining's auc: 0.746455\ttraining's binary_logloss: 0.127032\tvalid_1's auc: 0.713343\tvalid_1's binary_logloss: 0.127197\n",
      "Fold Validation complex model ROC AUC: 0.7133431623316913\n",
      "Overall Validation Complex Model ROC AUC: 0.7046001554700715 ± 0.007611221364229935\n"
     ]
    }
   ],
   "source": [
    "cv = GroupKFold(n_splits=3)\n",
    "\n",
    "# Initialize list to store results\n",
    "valid_roc_aucs = []\n",
    "\n",
    "# Initialize the LGBMClassifier\n",
    "lgbm_model = LGBMClassifier(\n",
    "    force_col_wise=True, \n",
    "    random_state=42,\n",
    "    extra_trees=True,\n",
    "    n_estimators=2000,\n",
    "    num_leaves=54,\n",
    "    boosting_type='gbdt',\n",
    "    objective='binary',\n",
    "    learning_rate=0.03,\n",
    "    l1_regularization=0.1,\n",
    "    l2_regularization=10,\n",
    "    max_depth=-1,\n",
    "    min_data_in_leaf=20,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "# Perform GroupKFold cross-validation\n",
    "for idx_train, idx_valid in cv.split(X_scaled, y, groups=weeks):\n",
    "    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "    \n",
    "    # Train the model\n",
    "    lgbm_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=100)]\n",
    "    )\n",
    "    # Predict on validation set\n",
    "    y_valid_pred_proba = lgbm_model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    # Evaluate model on validation set\n",
    "    valid_roc_auc = roc_auc_score(y_valid, y_valid_pred_proba)\n",
    "    valid_roc_aucs.append(valid_roc_auc)\n",
    "\n",
    "    print(f'Fold Validation complex model ROC AUC: {valid_roc_auc}')\n",
    "\n",
    "# Output overall validation results\n",
    "print(f'Overall Validation Complex Model ROC AUC: {np.mean(valid_roc_aucs)} ± {np.std(valid_roc_aucs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, extra_trees=True,\n",
       "               feature_fraction=0.8, force_col_wise=True, l1_regularization=0.1,\n",
       "               l2_regularization=10, learning_rate=0.03, min_data_in_leaf=20,\n",
       "               n_estimators=2000, num_leaves=54, objective=&#x27;binary&#x27;,\n",
       "               random_state=42, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, extra_trees=True,\n",
       "               feature_fraction=0.8, force_col_wise=True, l1_regularization=0.1,\n",
       "               l2_regularization=10, learning_rate=0.03, min_data_in_leaf=20,\n",
       "               n_estimators=2000, num_leaves=54, objective=&#x27;binary&#x27;,\n",
       "               random_state=42, verbose=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, extra_trees=True,\n",
       "               feature_fraction=0.8, force_col_wise=True, l1_regularization=0.1,\n",
       "               l2_regularization=10, learning_rate=0.03, min_data_in_leaf=20,\n",
       "               n_estimators=2000, num_leaves=54, objective='binary',\n",
       "               random_state=42, verbose=-1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model.fit(\n",
    "    X_scaled, y,\n",
    "    eval_metric='auc',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the complexity of the classifier does not provide the additional value for our predictions, my oppinion is to try forward the ensembels techniques for improvement teh efficiency of the oredictins, or to return to base model which shows robust results on all cross_folds ±0.0002\n",
    "BASE LINE -Overall Validation ROC AUC is: 0.6998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            score\n",
      "case_id          \n",
      "57543    0.130243\n",
      "57549    0.113207\n",
      "57551    0.140332\n",
      "57552    0.140332\n",
      "57569    0.137036\n",
      "57630    0.133266\n",
      "57631    0.142977\n",
      "57632    0.124476\n",
      "57633    0.129617\n",
      "57634    0.126474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_data.drop(columns=['WEEK_NUM', 'target']).set_index('case_id')\n",
    "\n",
    "# Predict on test set (assuming you have a separate test set)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_pred_proba = lgbm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "sample = pd.read_csv('/Users/nataliamarko/Documents/Kaggle/home_credit_risk_score/sample_submission.csv')\n",
    "sample = sample.set_index('case_id')\n",
    "predictions = pd.DataFrame(y_test_pred_proba, index=X_test.index)\n",
    "\n",
    "# Assign the predictions to the 'score' column in the sample submission\n",
    "sample['score'] = predictions\n",
    "print(sample)\n",
    "\n",
    "sample.to_csv(\"submission.csv\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7921029,
     "sourceId": 50160,
     "sourceType": "competition"
    },
    {
     "datasetId": 5044429,
     "sourceId": 8462029,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
